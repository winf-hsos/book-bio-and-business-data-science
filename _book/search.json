[
  {
    "objectID": "case-campusbier.html",
    "href": "case-campusbier.html",
    "title": "Fall: Campusbier",
    "section": "",
    "text": "Die Campusbier-Fallstudie ist in dem Sinne eine besondere Fallstudie im Rahmen dieses Buches, als dass sie als Einführung in das Basishandwerkszeug mit R dient. Wenn die Zeit für nur eine Fallstudie ausreicht und man Anfänger mit der Datenanalyse mit R ist, dann ist diese Fallstudie die richtige. Sie steht deshalb auch am Anfang des Buches und dient in allen meinen Modulen zur Datenanalyse mit R als Gegenstand der Einführung.\nDas Campusbier-Projekt beschäftigt sich mit der Vermarktung des hochschuleigenen Bieres, das 2009 von Studierenden auf der Versuchsbrauanlage der Hochschule Osnabrück entwickelt wurde. Im Jahr 2019 wurde das Bier erstmals in größerer Menge gebraut und in Flaschen abgefüllt, so dass es der Osnabrücker Bevölkerung zugänglich gemacht werden konnte. Zuvor war das Bier nur intern in Fässern erhältlich, die etwa für Veranstaltungen am Campus der Hochschule verwendet wurden. Die erste öffentliche Verkaufsrunde im Mai/Juni 2019 war ein voller Erfolg, was zu einer dauerhaften Verfügbarkeit des Bieres über den Onlie-Shop campusbier.de führte. Seitdem sind in vielen Projekten weitere Aktionen und Produkte hinzugekommen, deren Verkäufe sich im vorliegenden Datensatz wiederspiegeln."
  },
  {
    "objectID": "case-campusbier.html#der-datensatz",
    "href": "case-campusbier.html#der-datensatz",
    "title": "Fall: Campusbier",
    "section": "Der Datensatz",
    "text": "Der Datensatz\nDer Datensatz besteht aus den Informationen zu den knapp 3000 Bestellungen, die in den Jahren 2019 bis 2022 über den Online-Shop aufgegeben wurden. Neben den Metadaten einer Bestellung, wie der Bestellzeitpunkt, der Kunde oder die Zahlungsart, gibt es auch die Informationen über die gekauften Produkte, also den Warenkorb jeder Bestellung. Diese Daten liegen als CSV-Exporte aus dem E-Commerce-System Shopify vor. Der Datensatz besteht aus den beiden Dateien orders.csv und line_items.csv. Um dem Datenschutz Rechnung zu tragen, wurden sämtliche persönliche Daten der Kunden entfernt. Jeder Kunde ist nur über eine technische Nummer identifizierbar, die in jeder Bestellung angegeben ist. Haben mehrere Bestellungen die gleiche Kundennummer, so stammen diese alle vom selben Kunden.\n\n\n\n\n\n\nLadet euch am besten jetzt die beiden Dateien in euer Arbeitsverzeichnis herunter. Hier die Links zum Download (rechte Maustaste, “Link speichern unter”):\n\norders.csv\nline_items.csv"
  },
  {
    "objectID": "read-csv-files.html",
    "href": "read-csv-files.html",
    "title": "\n1  CSV-Dateien einlesen\n",
    "section": "",
    "text": "Im ersten Schritt jeder Datenanalyse müssen wir unserem Computer den Datensatz zur Verfügung stellen. Wir sprechen dabei auch vom Laden des Datesatzes. Dabei sagen wir dem Computer, wo die Daten zu finden sind und dass er sie für den schnelleren Zugriff in seinen Arbeitsspeicher holen soll.\nDaten liegen in den meisten Fällen in Form von Dateien vor. In manchen Fällen sind sie auch in einer Datenbank gespeichert. Im Fall einer Datei kann ein Datensatz in unterschiedlichen Formaten darin gespeichert werden. Ein gängiges Format ist das CSV-Format, das auf einfachen Textdateien basiert."
  },
  {
    "objectID": "read-csv-files.html#das-csv-format",
    "href": "read-csv-files.html#das-csv-format",
    "title": "\n1  CSV-Dateien einlesen\n",
    "section": "\n1.1 Das CSV-Format",
    "text": "1.1 Das CSV-Format\nCSV als weit verbreitetes Format\nFür die Speicherung von Daten bieten sich textuelle Formate an, weil sie auf jedem Betriebsystem mit einem einfachen Texteditor betrachtet und bearbeitet werden können. Das ermöglicht das einfache Teilen von Daten und somit die Zusammenarbeit. Auch für den Datenaustausch zwischen verschiedenen Informationssystemen wird häufig ein textbasiertes Format verwendet, um spezifisches Formate der jeweiligen Hersteller, wie etwa proprieäte Datenbanken, zu überbrücken. Deshalb bieten die meisten Informationssysteme Schnittstellen für den Export und Import von Textdateien an. Speziell das CSV-Format ist hier sehr beliebt, aus guten Gründen:\n\nDie Verwendung von einfachen Textdateien erlaubt die Speicherung und Verarbeitung auf unterschiedlichen Umgebungen wie Windows, macOS oder Linux.\nDas Format ist einfach zu verstehen und auch für Menschen lesbar.\nCSV ist ein offenes Format, d. h. es gibt keine Organisation, die daran die Rechte besitzt und es kann daher von jeder Software verwendet werden. Es gab lange nicht einmal eine offizielle Spezifikation des Formats. Mittlerweile gibt es eine Spezifikation als offizieller MIME Type.\n\nAuch das E-Commerce-System Shopify, aus dem die vorligenden Verkaufsdaten stammen, bietet eine Möglichkeit zum Exportieren von Textdateien im sogenannten CSV-Format an.\nCSV eignet sich für strukturierte Daten\nCSV steht für Comma Separated Values und beschreibt ein Format, um strukturierte Daten in einer Textdatei abzuspeichern. Ihr erkennt eine Textdatei im CSV-Format an der Endung .csv.\nDas CSV-Format basiert auf einfachen Textkodierungen, häufig im UTF-8 oder ASCII-Kodierungssystem (letzeres immer seltener wegen der geringen Anzahl verfügbarer Zeichen), die mit fast jedem Werkzeug und Editor gelesen und bearbeitet werden können. Zusätzlich bildet das CSV-Format eine tabellarische Struktur ab, bei dem die Daten in Zeilen und Spalten getrennt werden. Alle darauf folgenden Zeilen stellen Beobachtungen oder Datensätze dar, deren Variablenwerte mit dem gleichen Trennzeichen abgegrenzt werden.\nDas CSV-Format speichert strukturierte Daten in einer tabellarischen Form, ähnlich wie in Spreadsheets. Die erste Zeile einer CSV-Datei ist üblicherweise der sogenannte Header (Kopfzeile) und beinhaltet die Spaltennamen mit Kommata oder Semikolon (Trennzeichen) voneinander getrennt. Jede weitere Zeile stellt eine Beobachtung (Englisch: observation oder case) oder auch Datensatz (Englisch: record) dar. Jeder Datensatz enthält für die im Header definierten Attribute (oder Spalten) einen Wert, die durch das gleiche Trennzeichen voneinander getrennt sind. Es muss nicht jeder Spaltenwert existieren. Sollte ein Wert für eine Beobachtung nicht vorhanden sein, so wird einfach nach dem Komma nichts eingetragen und es folgen zwei Kommata nacheinander. In R werden fehlende Werte mit NA gekennzeichnet.\nDie Verwendung des Komma als Trennzeichen in CSV-Dateien ist keineswegs verbindlich, auch wenn es Bestandteil des Namens ist. Generell kann jedes Symbol verwendet werden. Häufige Alternativen sind das Semikolon, Leerzeichen oder ein Tabstop. Letzteres wird oft mit der eigenen Endung .tsv für Tab Separated Values gespeichert.\nBeispiel einer CSV-Datei\nDer Auschnitt unten zeigt die ersten vier Zeilen der orders.csv. Die erste Zeile enthält die Namen der hier gezeigten vier Spalten (der Datensatz hat mehr Spalten, das ist nur ein Auszug), die mit einem Komma voneinander getrennt sind. Darunter folgen drei beispielhafte Datensätze:\nid,order_id,name,order_number,app_id,created_at\n1130007101519,B1014,1014,580111,2019-05-24T14:59:16+02:00\n1130014965839,B1015,1015,580111,2019-05-24T15:09:08+02:00\n1130026958927,B1016,1016,580111,2019-05-24T15:22:41+02:00\n..."
  },
  {
    "objectID": "read-csv-files.html#csv-daten-laden-mit-readr",
    "href": "read-csv-files.html#csv-daten-laden-mit-readr",
    "title": "\n1  CSV-Dateien einlesen\n",
    "section": "\n1.2 CSV-Daten laden mit {readr}\n",
    "text": "1.2 CSV-Daten laden mit {readr}\n\nAus einer lokalen Datei\nFür das Laden Datensätzen aus CSV-Dateien bietet das Tidyverse ein eigenes Paket namens readr an. Dieses wird automatisch mit dem tidyverse-Paket mitgeladen. Das Paket bietet für CSV-Dateien, bei denen das Komma als Trennzeichen verwendet wird, die Funktion read_csv an:\n\norders <- read_csv(\"./data/orders.csv\")\n\nAuch der R-Basisumfang bietet eine ähnliche Funktion für genau diesen Anwendungsfall an. Diese heisst read.csv, man achte hier auf das Detail: Statt eines Unterstrichs wird bei der R-Basisfunktion ein Punkt zwischen den beiden Wörtern read und csv verwendet. Wenn ihr mit dem Tidyverse und mit Tibbles arbeitet (wie in diesem Buch durchgängig), dann achtet darauf immer die readr-Funktion read_csv zu verwenden, weil nur diese die Daten als Tibble zurückgibt und zudem noch ein paar nützliche Zusatzfunktionen bietet.\nNur bestimmte Spalten laden\nDie read_csv-Funktion erlaubt direkt beim Laden der Daten eine Auswahl der Spalten vorzunehmen. Ich empfehle hier immer die Verwendung der select-Funktion, die wir im nächsten Abschnitt kennenlernen werden. Dennoch möchte ich kurz demonstrieren, wie das Filtern der Spalten beim Laden funktioniert.\nDer folgende Code lädt die Spalten order_id, name, sowie alle Spalten, deren Name mit “customer” beginnen:\n\norders <- read_csv(\"./data/orders.csv\", col_select = c(order_id, name, starts_with(\"customer\")))\n\nIm Ergebnis ist der resultierende Tibble dann sehr viel schmaler und beinhaltet nur die gewünschten Spalten:\n\ncolnames(orders)\n\n [1] \"order_id\"                             \n [2] \"name\"                                 \n [3] \"customer_id\"                          \n [4] \"customer_accepts_marketing\"           \n [5] \"customer_accepts_marketing_updated_at\"\n [6] \"customer_marketing_opt_in_level\"      \n [7] \"customer_sms_marketing_consent\"       \n [8] \"customer_created_at\"                  \n [9] \"customer_updated_at\"                  \n[10] \"customer_gender\"                      \n[11] \"customer_is_hsos\"                     \n[12] \"customer_state\"                       \n[13] \"customer_orders_count\"                \n[14] \"customer_total_spent\"                 \n[15] \"customer_last_order_id\"               \n[16] \"customer_note\"                        \n[17] \"customer_verified_email\"              \n[18] \"customer_tax_exempt\"                  \n[19] \"customer_tags\"                        \n[20] \"customer_last_order_name\"             \n\n\nHat man nur eine Filterbedingung, so kann man sich die c()-Funktion auch sparen:\n\norders <- read_csv(\"./data/orders.csv\", col_select = starts_with(\"shipping\"))\n\nDas Ergebnis:\n\ncolnames(orders)\n\n[1] \"shipping_address_city\"      \"shipping_address_zip\"      \n[3] \"shipping_address_country\"   \"shipping_address_latitude\" \n[5] \"shipping_address_longitude\"\n\n\nIst man auf möglichst wenige Zeilen Code aus, so kann die Verwendung des col_types-Parameters durchaus Sinn ergeben. Man könnte den gleichen Effekt auch mit einem anschließenden select erzielen:\n\norders <- read_csv(\"./data/orders.csv\") %>% \n  select(starts_with(\"shipping\"))\n\nMehr zur Auswahl von Spalten mit dplyr erfahrt ihr im Abschnitt XY.\nRegionale Einstellungen\nDaten von einem Webserver laden\nDie CSV-Datei muss nicht lokal auf dem eigenen Rechner vorliegen, sondern kann mit read_csv über das HTTP-Protkoll direkt von einem Webserver im Internet abgerufen werden. Dabei wird die URL anstelle des lokalen Dateinamens der Funktion übergeben. Der Code unten lädt die tagesaktuelle Version des Covid-19-Datensatzes, der auf den Servern von Our World in Data gehostet wird:\n\ncovid <- read_csv(\"https://covid.ourworldindata.org/data/owid-covid-data.csv\")\n\nRows: 219868 Columns: 67\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr   (4): iso_code, continent, location, tests_units\ndbl  (62): total_cases, new_cases, new_cases_smoothed, total_deaths, new_dea...\ndate  (1): date\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "explore-new-data-sets.html",
    "href": "explore-new-data-sets.html",
    "title": "\n2  Datensätze erkunden\n",
    "section": "",
    "text": "Alleine beim Aufruf seines Namens gibt ein Tibble in der Konsole viele seiner Informationen preis:\n\norders\n\n# A tibble: 2,874 x 68\n     order_id name  order~1 app_id created_at          updated_at          test \n        <dbl> <chr>   <dbl>  <dbl> <dttm>              <dttm>              <lgl>\n 1    1.13e12 B1014    1014 580111 2019-05-24 12:59:16 2019-06-19 13:23:26 FALSE\n 2    1.13e12 B1015    1015 580111 2019-05-24 13:09:08 2019-06-21 14:40:07 FALSE\n 3    1.13e12 B1016    1016 580111 2019-05-24 13:22:41 2019-06-21 12:35:23 FALSE\n 4    1.13e12 B1017    1017 580111 2019-05-24 13:27:43 2019-06-21 14:27:18 FALSE\n 5    1.13e12 B1018    1018 580111 2019-05-24 13:36:46 2019-06-21 12:11:57 FALSE\n 6    1.13e12 B1019    1019 580111 2019-05-24 13:44:41 2019-06-21 14:37:21 FALSE\n 7    1.13e12 B1020    1020 580111 2019-05-24 13:49:21 2019-06-21 12:25:16 FALSE\n 8    1.13e12 B1021    1021 580111 2019-05-24 13:59:57 2019-06-21 11:49:47 FALSE\n 9    1.13e12 B1022    1022 580111 2019-05-24 14:43:53 2019-06-19 14:12:38 FALSE\n10    1.13e12 B1023    1023 580111 2019-05-24 14:48:16 2019-06-21 15:54:24 FALSE\n# ... with 2,864 more rows, 61 more variables: current_subtotal_price <dbl>,\n#   current_total_price <dbl>, current_total_discounts <dbl>,\n#   current_total_duties_set <dbl>, total_discounts <dbl>,\n#   total_line_items_price <dbl>, total_outstanding <dbl>, total_price <dbl>,\n#   total_tax <dbl>, total_tip_received <dbl>, taxes_included <lgl>,\n#   discount_codes <chr>, financial_status <chr>, fulfillment_status <chr>,\n#   source_name <chr>, landing_site <chr>, landing_site_ref <chr>, ...\n\n\nNeben den ersten paar Zeilen als Vorschau gibt ein Tibble auch die Gesamtzahl an Zeilen und Spalten aus. Hier sind es 2874 Zeilen und 68 Spalten. Darunter folgt eine mit Kommata getrennte Auflistung der Spaltennamen und ihren Datentypen. Diese Liste wird aber nach wenigen Zeilen abgebrochen, um die Konsole nicht mit Text zu überladen.\n\n\n\n\n\n\nVersucht das einmal: Ladet die CSV-Datei statt mit read_csv mit der Funktion read.csv aus dem Basis-R. Gebt jetzt den Namen des Dataframes in die Konsole ein und drückt Enter. Was ist der Unterschied bei der Ausgabe? Was gefällt euch besser?"
  },
  {
    "objectID": "explore-new-data-sets.html#spalten-und-deren-datentypen",
    "href": "explore-new-data-sets.html#spalten-und-deren-datentypen",
    "title": "\n2  Datensätze erkunden\n",
    "section": "\n2.2 Spalten und deren Datentypen",
    "text": "2.2 Spalten und deren Datentypen\n\nspec(orders)\n\ncols(\n  order_id = col_double(),\n  name = col_character(),\n  order_number = col_double(),\n  app_id = col_double(),\n  created_at = col_datetime(format = \"\"),\n  updated_at = col_datetime(format = \"\"),\n  test = col_logical(),\n  current_subtotal_price = col_double(),\n  current_total_price = col_double(),\n  current_total_discounts = col_double(),\n  current_total_duties_set = col_double(),\n  total_discounts = col_double(),\n  total_line_items_price = col_double(),\n  total_outstanding = col_double(),\n  total_price = col_double(),\n  total_tax = col_double(),\n  total_tip_received = col_double(),\n  taxes_included = col_logical(),\n  discount_codes = col_character(),\n  financial_status = col_character(),\n  fulfillment_status = col_character(),\n  source_name = col_character(),\n  landing_site = col_character(),\n  landing_site_ref = col_character(),\n  location_id = col_double(),\n  note = col_character(),\n  tags = col_character(),\n  processed_at = col_datetime(format = \"\"),\n  processing_method = col_character(),\n  payment_details_gateway = col_character(),\n  payment_details_credit_card_company = col_character(),\n  customer_id = col_double(),\n  customer_accepts_marketing = col_double(),\n  customer_accepts_marketing_updated_at = col_datetime(format = \"\"),\n  customer_marketing_opt_in_level = col_character(),\n  customer_sms_marketing_consent = col_logical(),\n  customer_created_at = col_datetime(format = \"\"),\n  customer_updated_at = col_datetime(format = \"\"),\n  customer_gender = col_character(),\n  customer_is_hsos = col_double(),\n  customer_state = col_character(),\n  customer_orders_count = col_double(),\n  customer_total_spent = col_double(),\n  customer_last_order_id = col_double(),\n  customer_note = col_character(),\n  customer_verified_email = col_double(),\n  customer_tax_exempt = col_double(),\n  customer_tags = col_character(),\n  customer_last_order_name = col_character(),\n  campaign_tag = col_character(),\n  shipping_address_city = col_character(),\n  shipping_address_zip = col_double(),\n  shipping_address_country = col_character(),\n  shipping_address_latitude = col_double(),\n  shipping_address_longitude = col_double(),\n  billing_address_city = col_character(),\n  billing_address_zip = col_double(),\n  billing_address_country = col_character(),\n  billing_address_company = col_character(),\n  billing_address_latitude = col_double(),\n  billing_address_longitude = col_double(),\n  client_details_browser_ip = col_character(),\n  client_details_browser_height = col_double(),\n  client_details_browser_width = col_double(),\n  client_details_user_agent = col_character(),\n  cancel_reason = col_character(),\n  cancelled_at = col_datetime(format = \"\"),\n  closed_at = col_datetime(format = \"\")\n)"
  },
  {
    "objectID": "explore-new-data-sets.html#häufigkeiten-schnell-erfassen",
    "href": "explore-new-data-sets.html#häufigkeiten-schnell-erfassen",
    "title": "\n2  Datensätze erkunden\n",
    "section": "\n2.3 Häufigkeiten schnell erfassen",
    "text": "2.3 Häufigkeiten schnell erfassen\nMit dem bereits bekannten janitor-Paket erhalten wir eine Funktion, um für nominal skalierte Merkmale schnell die Häufigkeiten, sowohl absolut als auch prozentual, zu ermitteln:\n\nlibrary(janitor)\n\norders %>% \n  tabyl(payment_details_gateway)\n\n# A tibble: 4 x 4\n  payment_details_gateway     n  percent valid_percent\n  <chr>                   <int>    <dbl>         <dbl>\n1 manual                    194 0.0675          0.0675\n2 paypal                   1790 0.623           0.623 \n3 shopify_payments          889 0.309           0.309 \n4 <NA>                        1 0.000348       NA     \n\n\nWenn wir eine zweite Variable hinzufügen, so erstellt tabyl eine Kreuztabelle mit den absoluten Häufigkeiten der jeweiligen Kombinationen:\n\norders %>% \n  tabyl(payment_details_gateway, payment_details_credit_card_company)\n\n# A tibble: 4 x 5\n  payment_details_gateway `American Express` Mastercard  Visa   NA_\n  <chr>                                <dbl>      <dbl> <dbl> <dbl>\n1 manual                                   0          0     0   194\n2 paypal                                   0          1     3  1786\n3 shopify_payments                        14        372   303   200\n4 <NA>                                     0          0     0     1\n\n\nWir können so erkennen, dass für PayPal-Zahlungen nur sehr selten ein Kreditkartenanbieter hinterlegt ist. Bei den Shopify-Payments hingegen ist das in den meisten Bestellungen der Fall. Dabei liegt Mastercard knapp vor Visa, American Express ist eher die Ausnahme.\n\n\n\n\n\n\nEs wäre doch interessant zu wissen, warum genau eine Bestellung keine Angabe zur Zahlungsart besitzt. Prüft doch mal nach, welche das ist und versucht die Frage zu beantworten."
  },
  {
    "objectID": "long-wide-data.html",
    "href": "long-wide-data.html",
    "title": "4  Lange und breite Daten",
    "section": "",
    "text": "Wie bereits in Abschnitt Fall 2: Covid gesehen, können Daten in unterschiedlicher Form vorliegen."
  }
]